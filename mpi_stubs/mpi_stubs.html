<html>

  <head>
    <title>
      MPI_STUBS - Dummy MPI Library
    </title>
  </head>

  <body bgcolor="#EEEEEE" link="#CC0000" alink="#FF3300" vlink="#000055">

    <h1 align = "center">
      MPI_STUBS <br> Dummy MPI Library
    </h1>

    <hr>

    <p>
      <b>MPI_STUBS</b> 
      is a C library  which 
      implements "stub" versions of the MPI routines.
    </p>

    <p>
      <b>MPI_STUBS</b> is intended to include stubs for the most commonly 
      called MPI routines.  Most of the stub routines don't do anything.
      In a few cases, where it makes sense, they do some simple action
      or return a value that is appropriate for the serial processing
      case.
    </p>

    <p>
      <b>MPI_STUBS</b> can be used as a convenience, when a real MPI
      implementation is not available, and the user simply wants to
      test-compile a code.  It may also be useful in those occasions
      when a code has been so carefully written that it will still
      execute correctly on a single processor.
    </p>

    <p>
      <b>MPI_STUBS</b> is based on a similar package supplied as
      part of the <b>LAMMPS</b> program, which allow that program to
      be compiled, linked and run on a single processor machine,
      although it is normally intended for parallel execution.
    </p>

    <h3 align = "center">
      Licensing:
    </h3>

    <p>
      The computer code and data files described and made available on this web page 
      are distributed under
      <a href = "../../txt/gnu_lgpl.txt">the GNU LGPL license.</a>
    </p>

    <h3 align = "center">
      Languages:
    </h3>

    <p>
      <b>MPI_STUBS</b> is available in
      <a href = "../../c_src/mpi_stubs/mpi_stubs.html">a C version</a> and
      <a href = "../../cpp_src/mpi_stubs/mpi_stubs.html">a C++ version</a> and
      <a href = "../../f77_src/mpi_stubs/mpi_stubs.html">a FORTRAN77 version</a> and
      <a href = "../../f_src/mpi_stubs/mpi_stubs.html">a FORTRAN90 version</a>.
    </p>

    <h3 align = "center">
      Related Data and Programs:
    </h3>

    <p>
      <a href = "../../c_src/hello_mpi/hello_mpi.html">
      HELLO_MPI</a>,
      a C program which 
      prints out "Hello, world!" using the MPI parallel programming environment. 
    </p>

    <p>
      <a href = "../../examples/moab/moab.html">
      MOAB</a>,
      examples which
      illustrate the use of the MOAB job scheduler for a computer cluster.
    </p>

    <p>
      <a href = "../../c_src/mpi/mpi.html">
      MPI</a>,
      a library of message passing routines which
      enables parallel
      processing on a variety of machine architectures, and with
      a varying number of processors.
    </p>

    <p>
      <a href = "../../c_src/multitask_mpi/multitask_mpi.html">
      MULTITASK_MPI</a>,
      a C program which
      demonstrates how to "multitask", that is, to execute several unrelated
      and distinct tasks simultaneously, using MPI for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/random_mpi/random_mpi.html">
      RANDOM_MPI</a>, 
      a C program which
      demonstrates one way to generate the same sequence of random numbers
      for both sequential execution and parallel execution under MPI.
    </p>

    <h3 align = "center">
      Reference:
    </h3>

    <p>
      <ol>
        <li>
          William Gropp, Ewing Lusk, Anthony Skjellum,<br>
          Using MPI: Portable Parallel Programming with the
          Message-Passing Interface,<br>
          Second Edition,<br>
          MIT Press, 1999,<br>
          ISBN: 0262571323,<br>
          LC: QA76.642.G76.
        </li>
      </ol>
    </p>

    <h3 align = "center">
      Source Code:
    </h3>

    <p>
      <ul>
        <li>
          <a href = "mpi_stubs.c">mpi_stubs.c</a>, the source code.
        </li>
        <li>
          <a href = "mpi_stubs_c.h">mpi_stubs_c.h</a>, the include file.
        </li>
        <li>
          <a href = "mpi_stubs.sh">mpi_stubs.sh</a>,
          commands to compile the source code.
        </li>
      </ul>
    </p>

    <h3 align = "center">
      Examples and Tests:
    </h3>

    <p>
      <b>BUFFON_LAPLACE</b> demonstrates how parallel Monte Carlo
      processes can set up distinct random number streams.
      <ul>
        <li>
          <a href = "buffon_laplace.c">buffon_laplace.c</a>, 
          the source code;
        </li>
        <li>
          <a href = "buffon_laplace.sh">buffon_laplace.sh</a>,
          a shell script to compile and run the program;
        </li>
        <li>
          <a href = "buffon_laplace_output.txt">buffon_laplace_output.txt</a>,
          the resulting output;
        </li>
      </ul>
    </p>

    <p>
      <b>QUADRATURE</b> is a program that estimates an integral
      using the random sampling.
      <ul>
        <li>
          <a href = "quadrature.c">quadrature.c</a>,
          a sample calling program.
        </li>
        <li>
          <a href = "quadrature.sh">quadrature.sh</a>,
          commands to compile and run the sample program.
        </li>
        <li>
          <a href = "quadrature_output.txt">quadrature_output.txt</a>,
          the output from a run of the sample program.
        </li>
      </ul>
    </p>

    <h3 align = "center">
      List of Routines:
    </h3>

    <p>
      <ul>
        <li>
          <b>MPI_ALLGATHER</b> gathers data from all the processes in a communicator.
        </li>
        <li>
          <b>MPI_ALLGATHERV</b> gathers data from all the processes in a communicator.
        </li>
        <li>
          <b>MPI_ALLREDUCE</b> carries out a reduction operation.
        </li>
        <li>
          <b>MPI_BARRIER</b> forces processes within a communicator to wait together.
        </li>
        <li>
          <b>MPI_BCAST</b> broadcasts data from one process to all others.
        </li>
        <li>
          <b>MPI_CART_CREATE</b> creates a communicator for a Cartesian topology.
        </li>
        <li>
          <b>MPI_CART_GET</b> returns the "Cartesian coordinates" of the calling process.
        </li>
        <li>
          <b>MPI_CART_SHIFT</b> finds the destination and source for Cartesian shifts.
        </li>
        <li>
          <b>MPI_COMM_DUP</b> duplicates a communicator.
        </li>
        <li>
          <b>MPI_COMM_FREE</b> frees a communicator.
        </li>
        <li>
          <b>MPI_COMM_RANK</b> reports the rank of the calling process.
        </li>
        <li>
          <b>MPI_COMM_SIZE</b> reports the number of processes in a communicator.
        </li>
        <li>
          <b>MPI_COMM_SPLIT</b> splits up a communicator based on a key.
        </li>
        <li>
          <b>MPI_COPY_BYTE</b> copies a byte vector.
        </li>
        <li>
          <b>MPI_COPY_DOUBLE</b> copies a double vector.
        </li>
        <li>
          <b>MPI_COPY_FLOAT</b> copies a float vector.
        </li>
        <li>
          <b>MPI_COPY_INT</b> copies an int vector.
        </li>
        <li>
          <b>MPI_FINALIZE</b> shuts down the MPI library.
        </li>
        <li>
          <b>MPI_GET_COUNT</b> reports the actual number of items transmitted.
        </li>
        <li>
          <b>MPI_INIT</b> initializes the MPI library.
        </li>
        <li>
          <b>MPI_IRECV</b> receives data from another process.
        </li>
        <li>
          <b>MPI_ISEND</b> sends data from one process to another using nonblocking transmission.
        </li>
        <li>
          <b>MPI_RECV</b> receives data from another process within a communicator.
        </li>
        <li>
          <b>MPI_REDUCE</b> carries out a reduction operation.
        </li>
        <li>
          <b>MPI_REDUCE_DOUBLE</b> carries out a reduction operation on doubles.
        </li>
        <li>
          <b>MPI_REDUCE_FLOAT</b> carries out a reduction operation on floats.
        </li>
        <li>
          <b>MPI_REDUCE_INT</b> carries out a reduction operation on ints.
        </li>
        <li>
          <b>MPI_REDUCE_SCATTER</b> collects a message of the same length from each process.
        </li>
        <li>
          <b>MPI_RSEND</b> "ready sends" data from one process to another.
        </li>
        <li>
          <b>MPI_SEND</b> sends data from one process to another.
        </li>
        <li>
          <b>MPI_WAIT</b> waits for an I/O request to complete.
        </li>
        <li>
          <b>MPI_WAITALL</b> waits until all I/O requests have completed.
        </li>
        <li>
          <b>MPI_WAITANY</b> waits until one I/O requests has completed.
        </li>
        <li>
          <b>MPI_WTICK</b> returns the time between ticks of the timer.
        </li>
        <li>
          <b>MPI_WTIME</b> returns the elapsed wall clock time.
        </li>
        <li>
          <b>TIMESTAMP</b> prints the current YMDHMS date as a time stamp.
        </li>
      </ul>
    </p>

    <p>
      You can go up one level to <a href = "../c_src.html">
      the C source codes</a>.
    </p>

    <hr>

    <i>
      Last revised on 22 March 2011.
    </i>

    <!-- John Burkardt -->

  </body>

  <!-- Initial HTML skeleton created by HTMLINDEX. -->

</html>
